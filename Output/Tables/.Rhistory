result <- foreach(i = 1:numoit, .combine = "rbind", .packages = c("tcltk")) %dopar% {
#if(!exists("pb")) pb <- tkProgressBar("Parallel task", min=1, max=numoit)
#setTkProgressBar(pb, i)
n_hashtags <- sapply(strsplit(as.character(df[i,'hashtags']), " "), length)             #Number of Hashtags in Tweet --> NUMERIC
n_hashtags[is.na(df[i,'hashtags'])] <- 0
n_mentions<- sapply(strsplit(as.character(df[i,'mentions_screen_name']), " "), length)  #Number of Mentions in Tweet --> NUMERIC
n_mentions[is.na(df[i,'mentions_screen_name'])] <- 0
res[i,] <- cbind(n_hashtags,n_mentions)
res[i,]
}
on.exit(parallel::stopCluster(clu))
parallel::stopCluster(clu)
Avg_Hash_Count  <- mean(result$n_hashtags)
Avg_Ment_Count  <- mean(result$n_mentions)
Avg_Text_Leght  <- mean(df$word_count)
rm(res, result)
# Calculate Scores:
## Twitter Success Score:
Twitter_Success_Score <- ((Followers_Count/Account_age)^(1/10) + Tweets_Month^(1/10) + (Avg_Retweets+Avg_Favorites)^(1/10) + Friends_Count^(1/100)) / (1 + ((Retweet_Ratio + Quote_Ratio)^2))
#Order Data descending by status id (this way we get the latest meta information)
df <- df[order(-df$Status_id), ]
}
# Extract the two variables which are not always present
Last_Name  <- ifelse(is.na(match("Last_Name", names(df))), "", df[1,'Last_Name'])
First_Name <- ifelse(is.na(match("First_Name", names(df))), "", df[1,'First_Name'])
# Get Year and Month
Year <- format(Sys.Date(),"%Y")
Month<- format(Sys.Date(), "%m")
# Save Score in Data Frame colnames: User ID / Last-Name / First Name / Actor Type / Date (Year & Month) /
#                                    RTwitter_Success_Score :
rowline <- cbind(df[1,'User_id'], Last_Name, First_Name, df[1,'Akteur'], Year, Month, Twitter_Success_Score)
sorce_data[k,] <- rowline
}
View(sorce_data)
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 10000,
q = paste0("User_id:", userlist[k], " AND Datum:[",past, " TO ", today, "]"))
df <- df[["hits"]][["hits"]]
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:", userlist[k]))
df <- df[["hits"]][["hits"]]
userlist[k]
as.charcter(userlist[k])
as.character(userlist[k])
View(dfusers)
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "Name",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
View(dfusers)
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
dfusers <- users[["aggregations"]][["users"]][["buckets"]]
View(dfusers)
dfusers[["key"]] <- as.character(dfusers[["key"]])
as.character(dfusers[["key"]])
View(dfusers)
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
dfusers <- users[["aggregations"]][["users"]][["buckets"]]
dfusers <- data.frame(matrix(unlist(dfusers), nrow=length(dfusers), byrow=T),stringsAsFactors=T)
View(dfusers)
dfusers <- users[["aggregations"]][["users"]][["buckets"]]
dfusers <- data.frame(matrix(unlist(dfusers), nrow=length(dfusers), byrow=T),stringsAsFactors=T)
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 10000,
q = paste0("User_id:", userlist[k], " AND Datum:[",past, " TO ", today, "]"))
df <- df[["hits"]][["hits"]]
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:", userlist[k]))
df <- df[["hits"]][["hits"]]
userlist[k]
for(i in 1:length(dfusers)){
dfusers[[i]][["key"]] <- as.character(dfusers[[i]][["key"]])
}
length(dfusers)
nrow(dfusers)
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
dfusers <- users[["aggregations"]][["users"]][["buckets"]]
for(i in 1:length(dfusers)){
dfusers[[i]][["key"]] <- as.character(dfusers[[i]][["key"]])
}
View(dfusers)
dfusers <- data.frame(matrix(unlist(dfusers), nrow=length(dfusers), byrow=T),stringsAsFactors=F)
View(dfusers)
as.character(users[[i]][["key"]])
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
users <- users[["aggregations"]][["users"]][["buckets"]]
dfusers <- data.frame(matrix(unlist(dfusers), nrow=length(dfusers), byrow=T),stringsAsFactors=F)
for(i in 1:length(users)){
dfusers[i,1] <- as.character(users[[i]][["key"]])
}
View(dfusers)
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
users <- users[["aggregations"]][["users"]][["buckets"]]
dfusers[i,1]
dfusers[i,2]
dfusers[1,1]
View(dfusers)
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
users <- users[["aggregations"]][["users"]][["buckets"]]
dfusers <- data.frame(matrix(unlist(users), nrow=length(users), byrow=T),stringsAsFactors=F)
for(i in 1:length(users)){
dfusers[i,1] <- as.character(users[[i]][["key"]])
}
View(dfusers)
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 10000,
q = paste0("User_id:", userlist[k], " AND Datum:[",past, " TO ", today, "]"))
df <- df[["hits"]][["hits"]]
if(length(df) == 0) {
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:", userlist[k]))
df <- df[["hits"]][["hits"]]
df <- df[,-c(1,2,3,4)]
names(df) <- gsub('^[^.]*.', "", names(df)) #Removes all before the first point including the point
df$Status_id <- as.numeric(df$Status_id)
#No Posts in this month results in no Visibility hence score is ZEOR!
Twitter_Success_Score <- 0
} else {
# Adjust names of columns and delete first four columns:
df <- df[,-c(1,2,3,4)]
names(df) <- gsub('^[^.]*.', "", names(df)) #Removes all before the first point including the point
df$Status_id <- as.numeric(df$Status_id)
# Process Data of Tweets to calculate the Score:
Verified_Account<- df %>% filter(Status_id == max(as.numeric(df$Status_id), na.rm = T)) %>% select(Verified)
Tweets_Month    <- as.numeric(nrow(df))
Total_Tweets    <- max(as.numeric(df$Statuses_count), na.rm = T)
Avg_Retweets  <- max(as.numeric(df$Retweet_count), na.rm = T)
Avg_Favorites <- max(as.numeric(df$Favorite_count), na.rm = T)
Retweet_Ratio   <- mean(df$Is_retweet)
Quote_Ratio     <- mean(df$Is_quote)
Followers_Count <- max(as.numeric(df$Followers_count), na.rm = T)
Favourites_count<- max(as.numeric(df$Favourites_count), na.rm = T)
Friends_Count   <- max(as.numeric(df$Friends_count), na.rm = T)
Listed_count    <- max(as.numeric(df$Listed_count), na.rm = T)
Statuses_count  <- max(as.numeric(df$Statuses_count), na.rm = T)
Account_age     <- as.numeric(today - max(as.Date(df$Account_created_at), na.rm = T))
# Get some more complex figures:
clu <- makeCluster(2)
registerDoParallel(clu)
numoit <- nrow(df)
resi <- data.frame(matrix(NA, ncol = 3, nrow = numoit))
colnames(resi) <- c("hashtags", "mentions_screen_name", "word_count")
results <- foreach(i = 1:numoit, .combine = "rbind", .packages = c("stringr", "stringi", "dplyr", "tcltk")) %dopar% {
#if(!exists("pb")) pb <- tkProgressBar("Parallel task", min=1, max=numoit)
#setTkProgressBar(pb, i)
text <- df[i,'Text']
textall <- paste(df[i,'Retweet_text'], df[i,'Quoted_text'], df[i,'Text'], sep = " ")
hash <- str_extract_all(textall, "#\\S+")
ment <- str_extract_all(textall, "@\\S+")
text = gsub("&amp", "", text)
text = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", text)
text = gsub("@\\w+", "", text)
text = gsub("[[:punct:]]", "", text)
text = gsub("[[:digit:]]", "", text)
text = gsub("http\\w+", "", text)
text = gsub("[ \t]{2,}", "", text)
text = gsub("^\\s+|\\s+$", "", text)
word_count <- sapply(strsplit(text, " "), length)
hashtags <- list(hash[[1]])                                                             #Make list of all mentioned Hashtags
mentions_screen_name <- ifelse(list(ment[[1]]) == "character(0)", " ", list(ment[[1]])) #Make ist of all mentioned Uers
resi$hashtags[i] <- list(hashtags[[1]])                         #Format df$var[row_n] due to list input
resi$mentions_screen_name[i] <- list(mentions_screen_name[[1]]) #Format df$var[row_n] due to list input
resi[i, 'word_count'] <- word_count
resi[i,]
}
on.exit(parallel::stopCluster(clu))
parallel::stopCluster(clu)
df$hashtags <- results[,1]                #Make list of all mentioned Hashtags
df$mentions_screen_name <- results[,2]    #Make ist of all mentioned Uers
df$word_count <- results[,3]
rm(results, resi)
clu <- makeCluster(2)
registerDoParallel(clu)
res <- data.frame(matrix(NA, ncol = 2, nrow = numoit))
colnames(res) <- c("n_hashtags", "n_mentions")
result <- foreach(i = 1:numoit, .combine = "rbind", .packages = c("tcltk")) %dopar% {
#if(!exists("pb")) pb <- tkProgressBar("Parallel task", min=1, max=numoit)
#setTkProgressBar(pb, i)
n_hashtags <- sapply(strsplit(as.character(df[i,'hashtags']), " "), length)             #Number of Hashtags in Tweet --> NUMERIC
n_hashtags[is.na(df[i,'hashtags'])] <- 0
n_mentions<- sapply(strsplit(as.character(df[i,'mentions_screen_name']), " "), length)  #Number of Mentions in Tweet --> NUMERIC
n_mentions[is.na(df[i,'mentions_screen_name'])] <- 0
res[i,] <- cbind(n_hashtags,n_mentions)
res[i,]
}
on.exit(parallel::stopCluster(clu))
parallel::stopCluster(clu)
Avg_Hash_Count  <- mean(result$n_hashtags)
Avg_Ment_Count  <- mean(result$n_mentions)
Avg_Text_Leght  <- mean(df$word_count)
rm(res, result)
# Calculate Scores:
## Twitter Success Score:
Twitter_Success_Score <- ((Followers_Count/Account_age)^(1/10) + Tweets_Month^(1/10) + (Avg_Retweets+Avg_Favorites)^(1/10) + Friends_Count^(1/100)) / (1 + ((Retweet_Ratio + Quote_Ratio)^2))
#Order Data descending by status id (this way we get the latest meta information)
df <- df[order(-df$Status_id), ]
}
userlist <- c(as.character(dfusers$X1))
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 10000,
q = paste0("User_id:", userlist[k], " AND Datum:[",past, " TO ", today, "]"))
df <- df[["hits"]][["hits"]]
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:", userlist[k]))
df <- df[["hits"]][["hits"]]
userlist[k])
userlist[k]
View(dfusers)
969185938898345984
969185938898345984 == userlist[k]
paste0("User_id:", userlist[k])
969185938898345984
2^63
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
users <- users[["aggregations"]][["users"]][["buckets"]]
dfusers <- data.frame(matrix(unlist(users), nrow=length(users), byrow=T),stringsAsFactors=F)
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
users <- users[["aggregations"]][["users"]][["buckets"]]
dfusers <- data.frame(matrix(unlist(users), nrow=length(users), byrow=T),stringsAsFactors=F)
for(i in 1:length(users)){
dfusers[i,1] <- as.character(users[[i]][["key"]])
}
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 10000,
q = paste0("User_id:", userlist[k], " AND Datum:[",past, " TO ", today, "]"))
df <- df[["hits"]][["hits"]]
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:", userlist[k]))
df <- df[["hits"]][["hits"]]
#################################################################################################
### Get all Twitter user names which are in the Elastic DB:
aggs <- '{
"size": 0,
"aggs" : {
"users" : {
"terms" : { "field" : "User_id",  "size" : 10000 }
}
}}'
users <- Search(index = "digitaldemocracylab", type = "tweet",
body = aggs)
users <- users[["aggregations"]][["users"]][["buckets"]]
dfusers <- data.frame(matrix(unlist(users), nrow=length(users), byrow=T),stringsAsFactors=F)
for(i in 1:length(users)){
dfusers[i,1] <- as.character(users[[i]][["key"]])
}
View(dfusers)
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 10000,
q = paste0("User_id:", userlist[k], " AND Datum:[",past, " TO ", today, "]"))
df <- df[["hits"]][["hits"]]
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:", userlist[k]))
userlist[k]
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:", userlist[k]))
df <- df[["hits"]][["hits"]]
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:", userlist[k]))
df <- df[["hits"]][["hits"]]
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:'", userlist[k],"'"))
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
q = paste0("User_id:", userlist[k]))
aggs2 <- '{
"range": {
"User_id": {
"gte": 969185938898345000,
"lt": 969185938898347000
}
}
}'
df <- Search(index = "digitaldemocracylab", type = "tweet", asdf = TRUE, size = 1,
body = aggs2)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("arm", "bit64", "car", "caret", "chron", "cld2", "cronR", "devtools", "doParallel", "curl", "dplyr, "elastic", "foreach", "ggplot2", "glm2", "git2r", "gtools", "haven", "Hmisc", "httr", "iterators", "jsonlite", "lme4", "lubridate","magrittr", "MASS", "nnet", "openssl", "openxlsx", "pdftools", "plyr", "psych", "purrr", "quanteda","RColorBrewer", "Rccp", "Rcrawler", "RCurl", "readr", "reshape2", "rio", "rjson", "RJSONIO", "rstudiopi", "rtweet","rvest", "scales", "selectr", "SnowballC", "stopwords", "stringi", "stringr", "striprtf", "tm", "tidyr", "tokenizers","utf8", "XML", "xml2")
ipak(packages)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("arm", "bit64", "car", "caret", "chron", "cld2", "cronR", "devtools", "doParallel", "curl", "dplyr", "elastic", "foreach", "ggplot2", "glm2", "git2r", "gtools", "haven", "Hmisc", "httr", "iterators", "jsonlite", "lme4", "lubridate","magrittr", "MASS", "nnet", "openssl", "openxlsx", "pdftools", "plyr", "psych", "purrr", "quanteda","RColorBrewer", "Rccp", "Rcrawler", "RCurl", "readr", "reshape2", "rio", "rjson", "RJSONIO", "rstudiopi", "rtweet","rvest", "scales", "selectr", "SnowballC", "stopwords", "stringi", "stringr", "striprtf", "tm", "tidyr", "tokenizers","utf8", "XML", "xml2")
ipak(packages)
cat("File with Accounts to Stream Tweets is missing!\nThe script terminated without collecting any data!\nPlease add the File with the Accounts to stream in the right directory!\n")
cat("File with Accounts to Stream Tweets is missing!\nThe script terminated without collecting any data!\nPlease add the File with the Accounts to stream in the right directory!\n")
Account_Lists <- "C:/Test/Listen/AccountListen/"
cat("File with Accounts to Stream Tweets is missing!\nThe script terminated without collecting any data!\nPlease add the file with the accounts to stream in the right directory!\nThe directory is called ", Account_Lists,"!\n")
if(is.null(lastid)){
cat("File with Accounts to Stream Tweets is missing!\nThe script terminated without collecting any data!\nPlease add the file with the accounts to stream in the right directory!\nThe directory is called ", Account_Lists,"!\n")
break()
}
cat("File with Accounts to Stream Tweets is missing!\nThe script terminated without collecting any data!\n
Please add the file with the accounts to stream in the right directory!\nThe directory is called ",
Account_Lists,"!\n")
cat("File with Accounts to Stream Tweets is missing!\nThe script terminated without collecting any data!
Please add the file with the accounts to stream in the right directory!\nThe directory is called ",
Account_Lists,"!\n")
cat("File with Accounts to Stream Tweets is missing!\nThe script terminated without collecting any data!
Please add the file with the accounts to stream in the right directory!\nThe directory is called ",
Account_Lists,"!\n")
cat("File with Accounts to Stream Tweets is missing!\nThe script terminated without collecting any data!
Please add the file with the accounts to stream in the right directory!\nThe directory is called ",
Account_Lists,"!\n")
cat("File with Accounts to Stream Tweets is missing!\nThe script terminated without collecting any data!
Please add the file with the accounts to stream in the right directory!\nThe directory is called ",
Account_Lists,"!\n")
cat(account_list$'Akteur'[i], "is no longer active in swiss politics and has been disabled in the list!\nIf you want to get new tweets from him again set the value in column Active to 1 instead of 0!\n" )
cat("is no longer active in swiss politics and has been disabled in the list!\nIf you want to get new tweets from him again set the value in column Active to 1 instead of 0!\n" )
cat( "is no longer active in swiss politics and has been disabled in the list!\nIf you want to get new tweets from this actor again\nset the value in column Active to 1 instead of 0!\n" )
cat(helper, "has no Twitter Account\n")
helper <- 0
cat(helper, "has no Twitter Account\n")
"end message\n"
###################################################################################################
# Content:
###################################################################################################
# 1) Dependencies
# 2) Twitter API Scraper
## 2.1) Setup
## 2.2) Get Statuses from Twitter and save them
###################################################################################################
# 1) Dependencies
###################################################################################################
library(rtweet)
tll
tll <- data.frame()
is.NULL(tll)
tll == NULL
tll == 0
tll == 1
tll <- is.null()
is.null(tll)
output2 <- installed.packages()
##########################################################################################
# 2) Dependencies
##########################################################################################
library(rtweet)
library(jsonlite)
library(rjson)
library(httr)
library(RCurl)
library(data.table)
library(readr)
library(dplyr)
library(rJava)
library(rJava)
library(rJava)
library(xlsx)
library(h2o)
library(readr)
library(data.table)
library(bit64)
library(dplyr)
library(car)
library(stringi)
library(stringr)
library(parallel)
library(doParallel)
library(foreach)
library(tcltk)
library(iterators)
library(textclean)
library(stargazer)
library(ggplot2)
library(scales)
library(magrittr)
library(reshape2)
# Leave at least one core for your system mabe even two if you want to do other stuff on it.
h2oServer <- h2o.init(ip="localhost", port=54321, max_mem_size="4g", nthreads=6)
model_path <- "/Users/Mael/CloudStation/Universitaet Zuerich/Master Thesis/Output/dl_grid_model_33"
# Load best Model int H2O
best_model <- h2o.loadModel(model_path)
model_path <- "/Users/Mael/CloudStation/Universitaet Zuerich/Master Thesis/Output/GirdSearch_Step_2/dl_grid_model_33"
# Load best Model int H2O
best_model <- h2o.loadModel(model_path)
plot(best_model, timestep = "duration", metric = "logloss")
plot(best_model, metric = "logloss")
plot(best_model, metric = "logloss"main="Scoring History", xlab="Epochs", ylab="Log lossl")
plot(best_model, metric = "logloss",main="Scoring History", xlab="Epochs", ylab="Log lossl")
plot(best_model, metric = "logloss", title ="Scoring History", xlab="Epochs", ylab="Log lossl")
plot(best_model, metric = "logloss")
title(main="main title", sub="sub-title",
xlab="x-axis label", ylab="y-axis label")
plot(best_model, metric = "logloss", title(main="Scoring History",
xlab="Epochs", ylab="Log loss"))
###################################################################################################
# 8) Terminate H2O
###################################################################################################
h2o.shutdown(prompt = FALSE)
paste0(year(ymd(Sys.Date())),"03-01")
lubridate
library(lubridate)
paste0(year(ymd(Sys.Date())),"03-01")
enddate <- if(month(ymd(Sys.Date())) < 3){
paste0(year(ymd(Sys.Date())),"-03-01")
} else if(month(ymd(Sys.Date())) < 6){
paste0(year(ymd(Sys.Date())),"-06-01")
} else if(month(ymd(Sys.Date())) < 9){
paste0(year(ymd(Sys.Date())),"-09-01")
} else {
paste0(year(ymd(Sys.Date())),"-12-01")
}
enddate <- as.Date(enddate, format = "%Y-%m-%d")
is.Date(enddate)
?rep()
setwd("~/CloudStation/Universitaet Zuerich/Master Thesis/Output/Tables")
library(readr)
Variance_of_classification_peak <- read_csv("Variance_of_classification_peak.csv")
View(Variance_of_classification_peak)
library(readr)
Variance_of_classification_peak <- read_csv("Variance_of_classification_peak.csv")
View(Variance_of_classification_peak)
